

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>PyTorch Implementation &mdash; SignXAI 1.0.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=fa44fd50" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../_static/custom.css?v=ec77c5b5" />

  
      <script src="../_static/jquery.js?v=5d32c60e"></script>
      <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../_static/documentation_options.js?v=8d563738"></script>
      <script src="../_static/doctools.js?v=9bcbadda"></script>
      <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Image Classification" href="../tutorials/image_classification.html" />
    <link rel="prev" title="TensorFlow Implementation" href="tensorflow.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"  style="background: #2980B9" >

          
          
          <a href="../index.html" class="icon icon-home">
            SignXAI
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="quickstart.html">Quickstart</a></li>
<li class="toctree-l1"><a class="reference internal" href="basic_usage.html">Basic Usage</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">User Guide</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="framework_interop.html">Framework Interoperability</a></li>
<li class="toctree-l1"><a class="reference internal" href="advanced_usage.html">Advanced Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="visualization.html">Visualization</a></li>
<li class="toctree-l1"><a class="reference internal" href="tensorflow.html">TensorFlow Implementation</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">PyTorch Implementation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="#key-components">Key Components</a></li>
<li class="toctree-l2"><a class="reference internal" href="#zennit-integration">Zennit Integration</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#what-is-zennit">What is Zennit?</a></li>
<li class="toctree-l3"><a class="reference internal" href="#how-signxai-uses-zennit">How SignXAI Uses Zennit</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#lrp-methods-in-detail">LRP Methods in Detail</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#lrp-epsilon">LRP-Epsilon</a></li>
<li class="toctree-l3"><a class="reference internal" href="#lrp-alphabeta">LRP-AlphaBeta</a></li>
<li class="toctree-l3"><a class="reference internal" href="#advanced-lrp-rules">Advanced LRP Rules</a></li>
<li class="toctree-l3"><a class="reference internal" href="#lrp-composite-rules">LRP Composite Rules</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#implementation-of-other-methods">Implementation of Other Methods</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#vanilla-gradient">Vanilla Gradient</a></li>
<li class="toctree-l3"><a class="reference internal" href="#integrated-gradients">Integrated Gradients</a></li>
<li class="toctree-l3"><a class="reference internal" href="#smoothgrad">SmoothGrad</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#removing-softmax-for-explainability">Removing Softmax for Explainability</a></li>
<li class="toctree-l2"><a class="reference internal" href="#dual-api-styles">Dual API Styles</a></li>
<li class="toctree-l2"><a class="reference internal" href="#usage-example">Usage Example</a></li>
<li class="toctree-l2"><a class="reference internal" href="#advanced-zennit-configuration">Advanced Zennit Configuration</a></li>
<li class="toctree-l2"><a class="reference internal" href="#sign-methods">SIGN Methods</a></li>
<li class="toctree-l2"><a class="reference internal" href="#performance-considerations">Performance Considerations</a></li>
<li class="toctree-l2"><a class="reference internal" href="#extending-with-new-methods">Extending with New Methods</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/image_classification.html">Image Classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/time_series.html">ECG Time Series</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../api/tensorflow.html">TensorFlow Module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/pytorch.html">PyTorch Module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/common.html">Common Module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/utils.html">Utilities</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/methods_list.html">Explanation Methods List</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu"  style="background: #2980B9" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">SignXAI</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">PyTorch Implementation</li>
      <li class="wy-breadcrumbs-aside">
              <a href="https://github.com/signxai/signxai/blob/main/docs/guide/pytorch.rst" class="fa fa-github"> Edit on GitHub</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="module-signxai.torch_signxai">
<span id="pytorch-implementation"></span><h1>PyTorch Implementation<a class="headerlink" href="#module-signxai.torch_signxai" title="Link to this heading"></a></h1>
<p>This guide provides a detailed explanation of SignXAI’s PyTorch implementation, with a focus on how the package integrates with Zennit for Layer-wise Relevance Propagation (LRP) methods.</p>
<nav class="contents local" id="contents">
<p class="topic-title">Contents</p>
<ul class="simple">
<li><p><a class="reference internal" href="#overview" id="id1">Overview</a></p></li>
<li><p><a class="reference internal" href="#key-components" id="id2">Key Components</a></p></li>
<li><p><a class="reference internal" href="#zennit-integration" id="id3">Zennit Integration</a></p>
<ul>
<li><p><a class="reference internal" href="#what-is-zennit" id="id4">What is Zennit?</a></p></li>
<li><p><a class="reference internal" href="#how-signxai-uses-zennit" id="id5">How SignXAI Uses Zennit</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#lrp-methods-in-detail" id="id6">LRP Methods in Detail</a></p>
<ul>
<li><p><a class="reference internal" href="#lrp-epsilon" id="id7">LRP-Epsilon</a></p></li>
<li><p><a class="reference internal" href="#lrp-alphabeta" id="id8">LRP-AlphaBeta</a></p></li>
<li><p><a class="reference internal" href="#advanced-lrp-rules" id="id9">Advanced LRP Rules</a></p></li>
<li><p><a class="reference internal" href="#lrp-composite-rules" id="id10">LRP Composite Rules</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#implementation-of-other-methods" id="id11">Implementation of Other Methods</a></p>
<ul>
<li><p><a class="reference internal" href="#vanilla-gradient" id="id12">Vanilla Gradient</a></p></li>
<li><p><a class="reference internal" href="#integrated-gradients" id="id13">Integrated Gradients</a></p></li>
<li><p><a class="reference internal" href="#smoothgrad" id="id14">SmoothGrad</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#removing-softmax-for-explainability" id="id15">Removing Softmax for Explainability</a></p></li>
<li><p><a class="reference internal" href="#dual-api-styles" id="id16">Dual API Styles</a></p></li>
<li><p><a class="reference internal" href="#usage-example" id="id17">Usage Example</a></p></li>
<li><p><a class="reference internal" href="#advanced-zennit-configuration" id="id18">Advanced Zennit Configuration</a></p></li>
<li><p><a class="reference internal" href="#sign-methods" id="id19">SIGN Methods</a></p></li>
<li><p><a class="reference internal" href="#performance-considerations" id="id20">Performance Considerations</a></p></li>
<li><p><a class="reference internal" href="#extending-with-new-methods" id="id21">Extending with New Methods</a></p></li>
</ul>
</nav>
<section id="overview">
<h2><a class="toc-backref" href="#id1" role="doc-backlink">Overview</a><a class="headerlink" href="#overview" title="Link to this heading"></a></h2>
<p>The PyTorch implementation in SignXAI provides powerful explainability methods for PyTorch models. It uses the Zennit library as the backend for Layer-wise Relevance Propagation (LRP) methods, providing state-of-the-art explanation capabilities with a clean API.</p>
</section>
<section id="key-components">
<h2><a class="toc-backref" href="#id2" role="doc-backlink">Key Components</a><a class="headerlink" href="#key-components" title="Link to this heading"></a></h2>
<ol class="arabic simple">
<li><p><strong>Dual API styles</strong> - Both PyTorch-native and TensorFlow-compatible interfaces</p></li>
<li><p><strong>Gradient-based methods</strong> - Vanilla gradient, Integrated gradients, SmoothGrad</p></li>
<li><p><strong>Guided Backpropagation</strong> - Enhanced gradient visualization</p></li>
<li><p><strong>Grad-CAM</strong> - Class activation mapping for CNNs</p></li>
<li><p><strong>LRP with Zennit</strong> - Layer-wise Relevance Propagation variants</p></li>
<li><p><strong>SIGN methods</strong> - Novel methods that use sign information</p></li>
</ol>
</section>
<section id="zennit-integration">
<h2><a class="toc-backref" href="#id3" role="doc-backlink">Zennit Integration</a><a class="headerlink" href="#zennit-integration" title="Link to this heading"></a></h2>
<p>The most powerful aspect of the PyTorch implementation is its integration with Zennit for LRP methods. This section explains how SignXAI leverages Zennit’s capabilities.</p>
<section id="what-is-zennit">
<h3><a class="toc-backref" href="#id4" role="doc-backlink">What is Zennit?</a><a class="headerlink" href="#what-is-zennit" title="Link to this heading"></a></h3>
<p><a class="reference external" href="https://github.com/chr5tphr/zennit">Zennit</a> is a PyTorch library for interpreting neural networks through LRP and other relevance propagation methods, developed at TU Berlin by Christopher J. Anders and colleagues. It offers:</p>
<ol class="arabic simple">
<li><p>Efficient implementation of various LRP rules</p></li>
<li><p>Flexible composite rule system for layer-specific rules</p></li>
<li><p>Native PyTorch integration with hooks and autograd</p></li>
</ol>
<div class="admonition-citation admonition">
<p class="admonition-title">Citation</p>
<p>If you use Zennit in your research through SignXAI, please consider citing the original work:</p>
<div class="highlight-bibtex notranslate"><div class="highlight"><pre><span></span><span class="nc">@article</span><span class="p">{</span><span class="nl">anders2021software</span><span class="p">,</span>
<span class="w">  </span><span class="na">author</span><span class="w">  </span><span class="p">=</span><span class="w"> </span><span class="s">{Anders, Christopher J. and</span>
<span class="s">             Neumann, David and</span>
<span class="s">             Samek, Wojciech and</span>
<span class="s">             Müller, Klaus-Robert and</span>
<span class="s">             Lapuschkin, Sebastian}</span><span class="p">,</span>
<span class="w">  </span><span class="na">title</span><span class="w">   </span><span class="p">=</span><span class="w"> </span><span class="s">{Software for Dataset-wide XAI: From Local Explanations to Global Insights with {Zennit}, {CoRelAy}, and {ViRelAy}}</span><span class="p">,</span>
<span class="w">  </span><span class="na">journal</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{CoRR}</span><span class="p">,</span>
<span class="w">  </span><span class="na">volume</span><span class="w">  </span><span class="p">=</span><span class="w"> </span><span class="s">{abs/2106.13200}</span><span class="p">,</span>
<span class="w">  </span><span class="na">year</span><span class="w">    </span><span class="p">=</span><span class="w"> </span><span class="s">{2021}</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<p>SignXAI integrates Zennit through a custom implementation in the <code class="docutils literal notranslate"><span class="pre">signxai.torch_signxai.methods.zennit_impl</span></code> module, allowing for:</p>
<ol class="arabic simple">
<li><p>Seamless integration with dependency management</p></li>
<li><p>Consistent API with the TensorFlow implementation</p></li>
<li><p>Implementation of SignXAI-specific features</p></li>
</ol>
</section>
<section id="how-signxai-uses-zennit">
<h3><a class="toc-backref" href="#id5" role="doc-backlink">How SignXAI Uses Zennit</a><a class="headerlink" href="#how-signxai-uses-zennit" title="Link to this heading"></a></h3>
<p>The integration happens primarily through the various analyzer classes in <code class="docutils literal notranslate"><span class="pre">signxai.torch_signxai.methods.zennit_impl</span></code>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">LRPAnalyzer</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Layer-wise Relevance Propagation (LRP) analyzer.</span>

<span class="sd">    Uses zennit&#39;s implementation of LRP with different rule variants.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">rule</span><span class="o">=</span><span class="s2">&quot;epsilon&quot;</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize LRP analyzer.</span>

<span class="sd">        Args:</span>
<span class="sd">            model: PyTorch model</span>
<span class="sd">            rule: LRP rule (&#39;epsilon&#39;, &#39;zplus&#39;, &#39;alphabeta&#39;)</span>
<span class="sd">            epsilon: Stabilizing factor for epsilon rule</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rule</span> <span class="o">=</span> <span class="n">rule</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span> <span class="o">=</span> <span class="n">epsilon</span>

        <span class="c1"># Map rule name to zennit composite</span>
        <span class="k">if</span> <span class="n">rule</span> <span class="o">==</span> <span class="s2">&quot;epsilon&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">composite</span> <span class="o">=</span> <span class="n">EpsilonGammaBox</span><span class="p">(</span><span class="n">epsilon</span><span class="o">=</span><span class="n">epsilon</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">rule</span> <span class="o">==</span> <span class="s2">&quot;zplus&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">composite</span> <span class="o">=</span> <span class="n">ZPlus</span><span class="p">()</span>
        <span class="k">elif</span> <span class="n">rule</span> <span class="o">==</span> <span class="s2">&quot;alphabeta&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">composite</span> <span class="o">=</span> <span class="n">AlphaBeta</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unknown LRP rule: </span><span class="si">{</span><span class="n">rule</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">analyze</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_tensor</span><span class="p">,</span> <span class="n">target_class</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate LRP attribution.</span>

<span class="sd">        Args:</span>
<span class="sd">            input_tensor: Input tensor</span>
<span class="sd">            target_class: Target class index (None for argmax)</span>

<span class="sd">        Returns:</span>
<span class="sd">            LRP attribution</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Set up attributor</span>
        <span class="n">attributor</span> <span class="o">=</span> <span class="n">Attributor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">composite</span><span class="p">)</span>

        <span class="c1"># Ensure input is a tensor and detach previous gradients</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="n">input_tensor</span> <span class="o">=</span> <span class="n">input_tensor</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">input_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># Forward pass</span>
        <span class="k">with</span> <span class="n">attributor</span><span class="p">:</span>
            <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">)</span>

            <span class="c1"># Get target class</span>
            <span class="k">if</span> <span class="n">target_class</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">target_class</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

            <span class="c1"># Create one-hot tensor</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">target_class</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="nb">hasattr</span><span class="p">(</span><span class="n">target_class</span><span class="p">,</span> <span class="s1">&#39;ndim&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">target_class</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
                <span class="n">one_hot</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
                <span class="n">one_hot</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">target_class</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">one_hot</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="bp">cls</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">target_class</span><span class="p">):</span>
                    <span class="n">one_hot</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="bp">cls</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span>

            <span class="c1"># Get attribution</span>
            <span class="n">attribution</span> <span class="o">=</span> <span class="n">attributor</span><span class="o">.</span><span class="n">attribute</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">,</span> <span class="n">output</span><span class="p">,</span> <span class="n">one_hot</span><span class="p">)</span>

        <span class="c1"># Return as numpy array</span>
        <span class="k">return</span> <span class="n">attribution</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</pre></div>
</div>
<p>This function combines Zennit’s powerful LRP implementation with SignXAI’s consistent interface.</p>
</section>
</section>
<section id="lrp-methods-in-detail">
<h2><a class="toc-backref" href="#id6" role="doc-backlink">LRP Methods in Detail</a><a class="headerlink" href="#lrp-methods-in-detail" title="Link to this heading"></a></h2>
<p>SignXAI provides several LRP variants through Zennit:</p>
<section id="lrp-epsilon">
<h3><a class="toc-backref" href="#id7" role="doc-backlink">LRP-Epsilon</a><a class="headerlink" href="#lrp-epsilon" title="Link to this heading"></a></h3>
<p>Adds a small epsilon value to stabilize the division operation:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Using PyTorch-native API</span>
<span class="n">explanation</span> <span class="o">=</span> <span class="n">calculate_relevancemap</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">input_tensor</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;lrp_epsilon&quot;</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>

<span class="c1"># Or via analyzer directly</span>
<span class="n">analyzer</span> <span class="o">=</span> <span class="n">LRPAnalyzer</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">rule</span><span class="o">=</span><span class="s2">&quot;epsilon&quot;</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="n">explanation</span> <span class="o">=</span> <span class="n">analyzer</span><span class="o">.</span><span class="n">analyze</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">,</span> <span class="n">target_class</span><span class="o">=</span><span class="n">class_idx</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="lrp-alphabeta">
<h3><a class="toc-backref" href="#id8" role="doc-backlink">LRP-AlphaBeta</a><a class="headerlink" href="#lrp-alphabeta" title="Link to this heading"></a></h3>
<p>Separates positive and negative contributions with different weights:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Using PyTorch-native API</span>
<span class="n">explanation</span> <span class="o">=</span> <span class="n">calculate_relevancemap</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">input_tensor</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;lrp_alphabeta&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Or via analyzer directly</span>
<span class="n">analyzer</span> <span class="o">=</span> <span class="n">LRPAnalyzer</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">rule</span><span class="o">=</span><span class="s2">&quot;alphabeta&quot;</span><span class="p">)</span>  <span class="c1"># Default alpha=1, beta=0</span>
<span class="n">explanation</span> <span class="o">=</span> <span class="n">analyzer</span><span class="o">.</span><span class="n">analyze</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">,</span> <span class="n">target_class</span><span class="o">=</span><span class="n">class_idx</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="advanced-lrp-rules">
<h3><a class="toc-backref" href="#id9" role="doc-backlink">Advanced LRP Rules</a><a class="headerlink" href="#advanced-lrp-rules" title="Link to this heading"></a></h3>
<p>For more complex LRP configurations, the <code class="docutils literal notranslate"><span class="pre">AdvancedLRPAnalyzer</span></code> can be used:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Using PyTorch-native API</span>
<span class="n">explanation</span> <span class="o">=</span> <span class="n">calculate_relevancemap</span><span class="p">(</span>
    <span class="n">model</span><span class="p">,</span>
    <span class="n">input_tensor</span><span class="p">,</span>
    <span class="n">method</span><span class="o">=</span><span class="s2">&quot;lrp_advanced&quot;</span><span class="p">,</span>
    <span class="n">rule_type</span><span class="o">=</span><span class="s2">&quot;alpha1beta0&quot;</span>
<span class="p">)</span>

<span class="c1"># Or for more control</span>
<span class="n">analyzer</span> <span class="o">=</span> <span class="n">AdvancedLRPAnalyzer</span><span class="p">(</span>
    <span class="n">model</span><span class="p">,</span>
    <span class="n">rule_type</span><span class="o">=</span><span class="s2">&quot;zbox&quot;</span><span class="p">,</span>
    <span class="n">low</span><span class="o">=-</span><span class="mf">123.68</span><span class="p">,</span>
    <span class="n">high</span><span class="o">=</span><span class="mf">151.061</span>
<span class="p">)</span>
<span class="n">explanation</span> <span class="o">=</span> <span class="n">analyzer</span><span class="o">.</span><span class="n">analyze</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">,</span> <span class="n">target_class</span><span class="o">=</span><span class="n">class_idx</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="lrp-composite-rules">
<h3><a class="toc-backref" href="#id10" role="doc-backlink">LRP Composite Rules</a><a class="headerlink" href="#lrp-composite-rules" title="Link to this heading"></a></h3>
<p>Applies different LRP rules to different layers of the network:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Using PyTorch-native API</span>
<span class="n">explanation</span> <span class="o">=</span> <span class="n">calculate_relevancemap</span><span class="p">(</span>
    <span class="n">model</span><span class="p">,</span>
    <span class="n">input_tensor</span><span class="p">,</span>
    <span class="n">method</span><span class="o">=</span><span class="s2">&quot;lrp_sequential&quot;</span><span class="p">,</span>
    <span class="n">first_layer_rule</span><span class="o">=</span><span class="s2">&quot;zbox&quot;</span><span class="p">,</span>
    <span class="n">middle_layer_rule</span><span class="o">=</span><span class="s2">&quot;alphabeta&quot;</span><span class="p">,</span>
    <span class="n">last_layer_rule</span><span class="o">=</span><span class="s2">&quot;epsilon&quot;</span>
<span class="p">)</span>

<span class="c1"># Or via analyzer directly</span>
<span class="n">analyzer</span> <span class="o">=</span> <span class="n">LRPSequential</span><span class="p">(</span>
    <span class="n">model</span><span class="p">,</span>
    <span class="n">first_layer_rule</span><span class="o">=</span><span class="s2">&quot;zbox&quot;</span><span class="p">,</span>
    <span class="n">middle_layer_rule</span><span class="o">=</span><span class="s2">&quot;alphabeta&quot;</span><span class="p">,</span>
    <span class="n">last_layer_rule</span><span class="o">=</span><span class="s2">&quot;epsilon&quot;</span>
<span class="p">)</span>
<span class="n">explanation</span> <span class="o">=</span> <span class="n">analyzer</span><span class="o">.</span><span class="n">analyze</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">,</span> <span class="n">target_class</span><span class="o">=</span><span class="n">class_idx</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="implementation-of-other-methods">
<h2><a class="toc-backref" href="#id11" role="doc-backlink">Implementation of Other Methods</a><a class="headerlink" href="#implementation-of-other-methods" title="Link to this heading"></a></h2>
<p>In addition to LRP methods, SignXAI provides Zennit-based implementations of other explainability techniques:</p>
<section id="vanilla-gradient">
<h3><a class="toc-backref" href="#id12" role="doc-backlink">Vanilla Gradient</a><a class="headerlink" href="#vanilla-gradient" title="Link to this heading"></a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">GradientAnalyzer</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Vanilla gradient analyzer.</span>

<span class="sd">    Implements vanilla gradient calculation aligned with TensorFlow&#39;s implementation.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize gradient analyzer.</span>

<span class="sd">        Args:</span>
<span class="sd">            model: PyTorch model</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>

    <span class="k">def</span> <span class="nf">analyze</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_tensor</span><span class="p">,</span> <span class="n">target_class</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate vanilla gradient attribution aligned with TensorFlow.</span>

<span class="sd">        Args:</span>
<span class="sd">            input_tensor: Input tensor</span>
<span class="sd">            target_class: Target class index (None for argmax)</span>

<span class="sd">        Returns:</span>
<span class="sd">            Gradient attribution</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Ensure input is a tensor with gradients</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="n">input_tensor</span> <span class="o">=</span> <span class="n">input_tensor</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">input_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># Forward pass</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">)</span>

        <span class="c1"># Get target class</span>
        <span class="k">if</span> <span class="n">target_class</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">target_class</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># Create one-hot tensor</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">target_class</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="nb">hasattr</span><span class="p">(</span><span class="n">target_class</span><span class="p">,</span> <span class="s1">&#39;ndim&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">target_class</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
            <span class="n">one_hot</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
            <span class="n">one_hot</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">target_class</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">one_hot</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="bp">cls</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">target_class</span><span class="p">):</span>
                <span class="n">one_hot</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="bp">cls</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span>

        <span class="c1"># Backward pass</span>
        <span class="n">output</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">gradient</span><span class="o">=</span><span class="n">one_hot</span><span class="p">)</span>

        <span class="c1"># Get gradients</span>
        <span class="n">attribution</span> <span class="o">=</span> <span class="n">input_tensor</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>

        <span class="c1"># Return as numpy array</span>
        <span class="k">return</span> <span class="n">attribution</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="integrated-gradients">
<h3><a class="toc-backref" href="#id13" role="doc-backlink">Integrated Gradients</a><a class="headerlink" href="#integrated-gradients" title="Link to this heading"></a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">IntegratedGradientsAnalyzer</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Integrated gradients analyzer.</span>

<span class="sd">    Implements the integrated gradients method by integrating gradients along a straight</span>
<span class="sd">    path from a baseline (typically zeros) to the input.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">steps</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">baseline</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize integrated gradients analyzer.</span>

<span class="sd">        Args:</span>
<span class="sd">            model: PyTorch model</span>
<span class="sd">            steps: Number of steps for integration</span>
<span class="sd">            baseline: Baseline input (None for zeros)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">steps</span> <span class="o">=</span> <span class="n">steps</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">baseline</span> <span class="o">=</span> <span class="n">baseline</span>

    <span class="k">def</span> <span class="nf">analyze</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_tensor</span><span class="p">,</span> <span class="n">target_class</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate integrated gradients attribution.</span>

<span class="sd">        Args:</span>
<span class="sd">            input_tensor: Input tensor</span>
<span class="sd">            target_class: Target class index (None for argmax)</span>

<span class="sd">        Returns:</span>
<span class="sd">            Integrated gradients attribution</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Implementation details...</span>
        <span class="c1"># ...</span>
        <span class="k">return</span> <span class="n">attribution</span>
</pre></div>
</div>
</section>
<section id="smoothgrad">
<h3><a class="toc-backref" href="#id14" role="doc-backlink">SmoothGrad</a><a class="headerlink" href="#smoothgrad" title="Link to this heading"></a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">SmoothGradAnalyzer</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;SmoothGrad analyzer.</span>

<span class="sd">    Implements SmoothGrad by adding Gaussian noise to the input multiple times and</span>
<span class="sd">    averaging the resulting gradients.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">noise_level</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize SmoothGrad analyzer.</span>

<span class="sd">        Args:</span>
<span class="sd">            model: PyTorch model</span>
<span class="sd">            noise_level: Level of Gaussian noise to add</span>
<span class="sd">            num_samples: Number of noisy samples to average</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">noise_level</span> <span class="o">=</span> <span class="n">noise_level</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_samples</span> <span class="o">=</span> <span class="n">num_samples</span>

    <span class="k">def</span> <span class="nf">analyze</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_tensor</span><span class="p">,</span> <span class="n">target_class</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate SmoothGrad attribution.</span>

<span class="sd">        Args:</span>
<span class="sd">            input_tensor: Input tensor</span>
<span class="sd">            target_class: Target class index (None for argmax)</span>

<span class="sd">        Returns:</span>
<span class="sd">            SmoothGrad attribution</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Implementation details...</span>
        <span class="c1"># ...</span>
        <span class="k">return</span> <span class="n">smoothgrad</span>
</pre></div>
</div>
</section>
</section>
<section id="removing-softmax-for-explainability">
<h2><a class="toc-backref" href="#id15" role="doc-backlink">Removing Softmax for Explainability</a><a class="headerlink" href="#removing-softmax-for-explainability" title="Link to this heading"></a></h2>
<p>Proper explainability often requires working with raw logits rather than softmax probabilities. SignXAI provides a wrapper to remove softmax from PyTorch models:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">remove_softmax</span><span class="p">(</span><span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Remove softmax layer from a PyTorch model.</span>

<span class="sd">    This function creates a copy of the model and removes the softmax activation,</span>
<span class="sd">    which is a common preprocessing step for explainability methods.</span>

<span class="sd">    Args:</span>
<span class="sd">        model: PyTorch model with softmax</span>

<span class="sd">    Returns:</span>
<span class="sd">        Model with softmax removed (copy)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Create a copy of the model</span>
    <span class="n">model_no_softmax</span> <span class="o">=</span> <span class="nb">type</span><span class="p">(</span><span class="n">model</span><span class="p">)()</span>
    <span class="n">model_no_softmax</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">get_state_dict</span><span class="p">())</span>
    <span class="n">model_no_softmax</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

    <span class="c1"># Wrap the model with NoSoftmaxWrapper which simply returns logits</span>
    <span class="k">return</span> <span class="n">NoSoftmaxWrapper</span><span class="p">(</span><span class="n">model_no_softmax</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">NoSoftmaxWrapper</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Wrapper class that removes softmax from a PyTorch model.</span>

<span class="sd">    This class wraps a PyTorch model and ensures the output is always logits,</span>
<span class="sd">    effectively removing any softmax activation in the forward pass.</span>

<span class="sd">    Args:</span>
<span class="sd">        model: PyTorch model with softmax</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize NoSoftmaxWrapper.</span>

<span class="sd">        Args:</span>
<span class="sd">            model: PyTorch model with softmax</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>  <span class="c1"># Set to evaluation mode</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Forward pass that returns logits directly (no softmax).</span>

<span class="sd">        Args:</span>
<span class="sd">            x: Input tensor</span>

<span class="sd">        Returns:</span>
<span class="sd">            Model output before softmax</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Forward pass through the model</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="c1"># Return unmodified output (logits)</span>
        <span class="k">return</span> <span class="n">output</span>
</pre></div>
</div>
</section>
<section id="dual-api-styles">
<h2><a class="toc-backref" href="#id16" role="doc-backlink">Dual API Styles</a><a class="headerlink" href="#dual-api-styles" title="Link to this heading"></a></h2>
<p>SignXAI provides two API styles for PyTorch users:</p>
<ol class="arabic simple">
<li><p><strong>PyTorch-Native API</strong> - More intuitive for PyTorch users</p></li>
</ol>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">signxai.torch_signxai</span> <span class="kn">import</span> <span class="n">calculate_relevancemap</span>

<span class="c1"># PyTorch-style API: model first, then input</span>
<span class="n">explanation</span> <span class="o">=</span> <span class="n">calculate_relevancemap</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">input_tensor</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;gradients&quot;</span><span class="p">)</span>
</pre></div>
</div>
<ol class="arabic simple" start="2">
<li><p><strong>TensorFlow-Compatible API</strong> - Consistent with the TensorFlow implementation</p></li>
</ol>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">signxai.torch_signxai.methods.wrappers</span> <span class="kn">import</span> <span class="n">calculate_relevancemap</span> <span class="k">as</span> <span class="n">tf_calculate_relevancemap</span>

<span class="c1"># TensorFlow-style API: method name first, then input, then model</span>
<span class="n">explanation</span> <span class="o">=</span> <span class="n">tf_calculate_relevancemap</span><span class="p">(</span><span class="s2">&quot;gradient&quot;</span><span class="p">,</span> <span class="n">input_tensor</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
<p>This dual API allows for easier migration between frameworks and preference-based usage.</p>
</section>
<section id="usage-example">
<h2><a class="toc-backref" href="#id17" role="doc-backlink">Usage Example</a><a class="headerlink" href="#usage-example" title="Link to this heading"></a></h2>
<p>The following example demonstrates how to use SignXAI’s PyTorch implementation with Zennit for generating LRP explanations:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torchvision.models</span> <span class="k">as</span> <span class="nn">models</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">from</span> <span class="nn">signxai.torch_signxai</span> <span class="kn">import</span> <span class="n">calculate_relevancemap</span>
<span class="kn">from</span> <span class="nn">signxai.torch_signxai.utils</span> <span class="kn">import</span> <span class="n">remove_softmax</span>
<span class="kn">from</span> <span class="nn">signxai.common.visualization</span> <span class="kn">import</span> <span class="n">normalize_relevance_map</span><span class="p">,</span> <span class="n">relevance_to_heatmap</span><span class="p">,</span> <span class="n">overlay_heatmap</span>

<span class="c1"># Load pre-trained model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">vgg16</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

<span class="c1"># Remove softmax (required for proper explanations)</span>
<span class="n">model_no_softmax</span> <span class="o">=</span> <span class="n">remove_softmax</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>

<span class="c1"># Load and preprocess image</span>
<span class="n">img</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s2">&quot;example.jpg&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">resize</span><span class="p">((</span><span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">))</span>
<span class="n">img_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">img</span><span class="p">))</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="mf">255.0</span>
<span class="n">img_tensor</span> <span class="o">=</span> <span class="n">img_tensor</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># Add batch dimension</span>

<span class="c1"># Calculate relevance maps using different LRP methods</span>
<span class="n">lrp_eps</span> <span class="o">=</span> <span class="n">calculate_relevancemap</span><span class="p">(</span><span class="n">model_no_softmax</span><span class="p">,</span> <span class="n">img_tensor</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;lrp_epsilon&quot;</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="n">lrp_ab</span> <span class="o">=</span> <span class="n">calculate_relevancemap</span><span class="p">(</span><span class="n">model_no_softmax</span><span class="p">,</span> <span class="n">img_tensor</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;lrp_alphabeta&quot;</span><span class="p">)</span>
<span class="n">lrp_composite</span> <span class="o">=</span> <span class="n">calculate_relevancemap</span><span class="p">(</span>
    <span class="n">model_no_softmax</span><span class="p">,</span>
    <span class="n">img_tensor</span><span class="p">,</span>
    <span class="n">method</span><span class="o">=</span><span class="s2">&quot;lrp_sequential&quot;</span><span class="p">,</span>
    <span class="n">first_layer_rule</span><span class="o">=</span><span class="s2">&quot;zbox&quot;</span><span class="p">,</span>
    <span class="n">middle_layer_rule</span><span class="o">=</span><span class="s2">&quot;alphabeta&quot;</span><span class="p">,</span>
    <span class="n">last_layer_rule</span><span class="o">=</span><span class="s2">&quot;epsilon&quot;</span>
<span class="p">)</span>

<span class="c1"># Visualize relevance maps</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>

<span class="c1"># Original image</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Original&quot;</span><span class="p">)</span>

<span class="c1"># LRP-Epsilon</span>
<span class="n">norm_lrp_eps</span> <span class="o">=</span> <span class="n">normalize_relevance_map</span><span class="p">(</span><span class="n">lrp_eps</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
<span class="n">heatmap</span> <span class="o">=</span> <span class="n">relevance_to_heatmap</span><span class="p">(</span><span class="n">norm_lrp_eps</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">overlay_heatmap</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">img</span><span class="p">)</span><span class="o">/</span><span class="mf">255.0</span><span class="p">,</span> <span class="n">heatmap</span><span class="p">))</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;LRP-Epsilon&quot;</span><span class="p">)</span>

<span class="c1"># LRP-AlphaBeta</span>
<span class="n">norm_lrp_ab</span> <span class="o">=</span> <span class="n">normalize_relevance_map</span><span class="p">(</span><span class="n">lrp_ab</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
<span class="n">heatmap</span> <span class="o">=</span> <span class="n">relevance_to_heatmap</span><span class="p">(</span><span class="n">norm_lrp_ab</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">overlay_heatmap</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">img</span><span class="p">)</span><span class="o">/</span><span class="mf">255.0</span><span class="p">,</span> <span class="n">heatmap</span><span class="p">))</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;LRP-AlphaBeta&quot;</span><span class="p">)</span>

<span class="c1"># LRP-Composite</span>
<span class="n">norm_lrp_comp</span> <span class="o">=</span> <span class="n">normalize_relevance_map</span><span class="p">(</span><span class="n">lrp_composite</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
<span class="n">heatmap</span> <span class="o">=</span> <span class="n">relevance_to_heatmap</span><span class="p">(</span><span class="n">norm_lrp_comp</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">overlay_heatmap</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">img</span><span class="p">)</span><span class="o">/</span><span class="mf">255.0</span><span class="p">,</span> <span class="n">heatmap</span><span class="p">))</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;LRP-Composite&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="advanced-zennit-configuration">
<h2><a class="toc-backref" href="#id18" role="doc-backlink">Advanced Zennit Configuration</a><a class="headerlink" href="#advanced-zennit-configuration" title="Link to this heading"></a></h2>
<p>For advanced users, SignXAI exposes more detailed Zennit configurations:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">signxai.torch_signxai.methods.zennit_impl</span> <span class="kn">import</span> <span class="n">AdvancedLRPAnalyzer</span>
<span class="kn">from</span> <span class="nn">zennit.composites</span> <span class="kn">import</span> <span class="n">EpsilonPlusFlat</span>

<span class="c1"># Create custom composite with layer-specific rules</span>
<span class="kn">from</span> <span class="nn">zennit.composites</span> <span class="kn">import</span> <span class="n">LayerMapComposite</span>
<span class="kn">from</span> <span class="nn">zennit.rules</span> <span class="kn">import</span> <span class="n">Epsilon</span><span class="p">,</span> <span class="n">ZPlus</span><span class="p">,</span> <span class="n">Gamma</span>
<span class="kn">from</span> <span class="nn">zennit.types</span> <span class="kn">import</span> <span class="n">Convolution</span><span class="p">,</span> <span class="n">Linear</span>

<span class="c1"># Define layer mapping</span>
<span class="n">layer_map</span> <span class="o">=</span> <span class="p">{</span>
    <span class="n">Convolution</span><span class="p">:</span> <span class="n">ZPlus</span><span class="p">(),</span>  <span class="c1"># Use ZPlus for convolutional layers</span>
    <span class="n">Linear</span><span class="p">:</span> <span class="n">Epsilon</span><span class="p">(</span><span class="n">epsilon</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>  <span class="c1"># Use Epsilon for linear layers</span>
<span class="p">}</span>

<span class="c1"># Create analyzer with custom composite</span>
<span class="n">analyzer</span> <span class="o">=</span> <span class="n">AdvancedLRPAnalyzer</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">rule_type</span><span class="o">=</span><span class="s2">&quot;custom&quot;</span><span class="p">,</span> <span class="n">composite</span><span class="o">=</span><span class="n">LayerMapComposite</span><span class="p">(</span><span class="n">layer_map</span><span class="p">))</span>
<span class="n">explanation</span> <span class="o">=</span> <span class="n">analyzer</span><span class="o">.</span><span class="n">analyze</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">,</span> <span class="n">target_class</span><span class="o">=</span><span class="n">class_idx</span><span class="p">)</span>
</pre></div>
</div>
<p>This flexibility allows for very fine-grained control over the explanation process.</p>
</section>
<section id="sign-methods">
<h2><a class="toc-backref" href="#id19" role="doc-backlink">SIGN Methods</a><a class="headerlink" href="#sign-methods" title="Link to this heading"></a></h2>
<p>SignXAI implements the novel SIGN methods for PyTorch models:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">signxai.torch_signxai.methods.signed</span> <span class="kn">import</span> <span class="n">calculate_sign_mu</span>

<span class="c1"># Calculate sign with threshold mu</span>
<span class="n">sign</span> <span class="o">=</span> <span class="n">calculate_sign_mu</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span>

<span class="c1"># Use with gradient-based methods</span>
<span class="n">grad</span> <span class="o">=</span> <span class="n">GradientAnalyzer</span><span class="p">(</span><span class="n">model</span><span class="p">)</span><span class="o">.</span><span class="n">analyze</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">)</span>
<span class="n">grad_sign</span> <span class="o">=</span> <span class="n">grad</span> <span class="o">*</span> <span class="n">sign</span>
</pre></div>
</div>
<p>This can be used with any of the analyzers to create SIGN variants of the methods.</p>
</section>
<section id="performance-considerations">
<h2><a class="toc-backref" href="#id20" role="doc-backlink">Performance Considerations</a><a class="headerlink" href="#performance-considerations" title="Link to this heading"></a></h2>
<p>When using Zennit through SignXAI, consider these performance tips:</p>
<ol class="arabic simple">
<li><p><strong>Model Complexity</strong> - LRP methods scale with model complexity</p></li>
<li><p><strong>Batch Size</strong> - Process multiple examples simultaneously for efficiency</p></li>
<li><p><strong>GPU Acceleration</strong> - Ensure PyTorch is using CUDA for better performance</p></li>
<li><p><strong>Memory Usage</strong> - For large models or inputs, consider gradient checkpointing</p></li>
<li><p><strong>Parallelization</strong> - Use DataParallel for multi-GPU setups</p></li>
</ol>
</section>
<section id="extending-with-new-methods">
<h2><a class="toc-backref" href="#id21" role="doc-backlink">Extending with New Methods</a><a class="headerlink" href="#extending-with-new-methods" title="Link to this heading"></a></h2>
<p>To add new methods, you can create a new analyzer class in <code class="docutils literal notranslate"><span class="pre">signxai.torch_signxai.methods.zennit_impl.py</span></code>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MyCustomAnalyzer</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Custom explanation method.</span>

<span class="sd">    Implements a custom explanation method using Zennit.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize custom analyzer.</span>

<span class="sd">        Args:</span>
<span class="sd">            model: PyTorch model</span>
<span class="sd">            **kwargs: Additional parameters</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="c1"># Setup any necessary parameters</span>

    <span class="k">def</span> <span class="nf">analyze</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_tensor</span><span class="p">,</span> <span class="n">target_class</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate custom attribution.</span>

<span class="sd">        Args:</span>
<span class="sd">            input_tensor: Input tensor</span>
<span class="sd">            target_class: Target class index (None for argmax)</span>

<span class="sd">        Returns:</span>
<span class="sd">            Custom attribution</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Implement custom attribution logic</span>
        <span class="c1"># ...</span>

        <span class="k">return</span> <span class="n">attribution</span>
</pre></div>
</div>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="tensorflow.html" class="btn btn-neutral float-left" title="TensorFlow Implementation" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../tutorials/image_classification.html" class="btn btn-neutral float-right" title="Image Classification" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2024, SignXAI Team.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>