{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# SignXAI with PyTorch - ECG Time Series Explanation\n\nThis tutorial demonstrates how to use SignXAI to explain ECG (electrocardiogram) predictions with PyTorch models. We'll be working with ECG data and a PyTorch model for detecting cardiac conditions.\n\n## Setup Requirements\n\nFor this PyTorch tutorial, you'll need to install SignXAI with PyTorch dependencies:\n\n```bash\n# For conda users\nconda create -n signxai-pytorch python=3.8\nconda activate signxai-pytorch\npip install -r ../../requirements/common.txt\npip install -r ../../requirements/pytorch.txt\n\n# Or for pip users\npython -m venv signxai_pytorch_env\nsource signxai_pytorch_env/bin/activate  # On Windows: signxai_pytorch_env\\Scripts\\activate\npip install -r ../../requirements/common.txt\npip install -r ../../requirements/pytorch.txt\n```\n\n## Overview\n\nWe'll cover:\n1. Loading ECG data and a PyTorch model\n2. Pre-processing ECG signals\n3. Applying PyTorch-based explainability methods to time series data\n4. Visualizing the regions of the ECG that influenced model predictions\n\nLet's get started!",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# SignXAI imports\n",
    "from signxai.torch_signxai.methods import SIGN, GradCAM, GuidedBackprop, LRPZ, LRPEpsilon\n",
    "from signxai.common.visualization import visualize_attribution\n",
    "from signxai.torch_signxai.utils import remove_softmax\n",
    "\n",
    "# Import utilities for ECG data handling\n",
    "# Ensure the utils directory is in the Python path\n",
    "sys.path.append(os.path.join(os.path.dirname(os.path.abspath(\"__file__\")), \"..\", \"utils\"))\n",
    "from pytorch.data import load_and_preprocess_ecg  # PyTorch-specific data loader\n",
    "from tensorflow.explainability import normalize_ecg_relevancemap  # This utility can be shared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Set Up Data Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up paths\n",
    "_THIS_DIR = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "DATA_DIR = os.path.realpath(os.path.join(_THIS_DIR, \"..\", \"..\", \"data\"))\n",
    "TIMESERIES_DIR = os.path.join(DATA_DIR, \"timeseries\")\n",
    "ECG_MODEL_PATH = os.path.join(DATA_DIR, \"models\", \"pytorch\", \"ECG\", \"ecg_model.pt\")\n",
    "\n",
    "# Check that model file exists\n",
    "assert os.path.exists(ECG_MODEL_PATH), f\"ECG model not found at {ECG_MODEL_PATH}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define a PyTorch ECG Model\n",
    "\n",
    "Let's first define a PyTorch model architecture for ECG processing. This is a 1D convolutional neural network designed for time series data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ECGModel(nn.Module):\n",
    "    def __init__(self, input_channels=1, sequence_length=2000):\n",
    "        super(ECGModel, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            # First convolutional block\n",
    "            nn.Conv1d(input_channels, 32, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2),  # 1000\n",
    "            \n",
    "            # Second convolutional block\n",
    "            nn.Conv1d(32, 64, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=4, stride=4),  # 250\n",
    "            \n",
    "            # Third convolutional block\n",
    "            nn.Conv1d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2),  # 125\n",
    "            \n",
    "            # Fourth convolutional block\n",
    "            nn.Conv1d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=5, stride=5),  # 25\n",
    "        )\n",
    "        \n",
    "        # Flatten and fully connected layers\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(256 * 25, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, 1),  # Binary classification\n",
    "            nn.Sigmoid()  # Use sigmoid for binary classification\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "    # Convenience method to get the last convolutional layer (for GradCAM)\n",
    "    def get_last_conv_layer(self):\n",
    "        return self.features[9]  # The 4th Conv1d layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load Model and ECG Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the PyTorch ECG model\n",
    "try:\n",
    "    ecg_model = torch.load(ECG_MODEL_PATH)\n",
    "    print(\"Loaded pre-trained ECG model\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not load saved model: {e}\\nInitializing new model instead\")\n",
    "    # Initialize a new model if loading fails\n",
    "    ecg_model = ECGModel()\n",
    "\n",
    "# Set model to evaluation mode\n",
    "ecg_model.eval()\n",
    "\n",
    "# Remove softmax/sigmoid for explainability methods\n",
    "ecg_model_no_softmax = remove_softmax(ecg_model)\n",
    "\n",
    "# Print model architecture\n",
    "print(ecg_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a sample ECG\n",
    "try:\n",
    "    # Try to load from saved numpy file\n",
    "    ecg_sample_path = os.path.join(TIMESERIES_DIR, \"ecg_sample.npy\")\n",
    "    ecg_data = np.load(ecg_sample_path)\n",
    "    print(f\"Loaded ECG sample from {ecg_sample_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not load ECG sample: {e}\\nGenerating synthetic data instead\")\n",
    "    # Generate synthetic ECG data if loading fails\n",
    "    # This is simplified and not realistic, just for illustration\n",
    "    from scipy import signal\n",
    "    t = np.linspace(0, 10, 2000)\n",
    "    ecg_data = signal.square(2 * np.pi * 1.2 * t, duty=0.3) + np.sin(2 * np.pi * 3 * t)\n",
    "    ecg_data += np.random.normal(0, 0.1, size=ecg_data.shape)\n",
    "\n",
    "# Plot the ECG data\n",
    "plt.figure(figsize=(15, 3))\n",
    "plt.plot(ecg_data)\n",
    "plt.title(\"ECG Sample\")\n",
    "plt.xlabel(\"Time (samples)\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Preprocess for PyTorch model (add channel dimension and batch dimension)\n",
    "ecg_tensor = torch.tensor(ecg_data, dtype=torch.float32).view(1, 1, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Get Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model prediction\n",
    "with torch.no_grad():\n",
    "    prediction = ecg_model(ecg_tensor)\n",
    "    prediction_probability = prediction.item()\n",
    "\n",
    "print(f\"Model prediction: {prediction_probability:.4f}\")\n",
    "print(f\"Diagnosis: {'Positive' if prediction_probability > 0.5 else 'Negative'} for abnormal ECG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Generate Explanations for the ECG Signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the explainability methods to use\n",
    "methods = {\n",
    "    'Gradient': SIGN(ecg_model_no_softmax),\n",
    "    'Gradient × Input': SIGN(ecg_model_no_softmax),  # Will be processed separately\n",
    "    'GradCAM': GradCAM(ecg_model_no_softmax, ecg_model.get_last_conv_layer()),\n",
    "    'Guided Backprop': GuidedBackprop(ecg_model_no_softmax),\n",
    "    'LRP-Z': LRPZ(ecg_model_no_softmax),\n",
    "    'LRP-Epsilon': LRPEpsilon(ecg_model_no_softmax, epsilon=0.5)\n",
    "}\n",
    "\n",
    "# Storage for explanations\n",
    "explanations = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target for binary classification (in PyTorch we typically need to specify a target)\n",
    "target = 0 if prediction_probability < 0.5 else 1\n",
    "\n",
    "# Generate explanations for each method\n",
    "for method_name, explainer in methods.items():\n",
    "    print(f\"Generating {method_name} explanation...\")\n",
    "    \n",
    "    if method_name == 'Gradient × Input':\n",
    "        # Special case for gradient × input\n",
    "        grad = explainer.attribute(ecg_tensor, target=target).detach().numpy()\n",
    "        explanation = grad * ecg_tensor.detach().numpy()\n",
    "    else:\n",
    "        explanation = explainer.attribute(ecg_tensor, target=target).detach().numpy()\n",
    "    \n",
    "    # Only use positive values for visualization\n",
    "    explanation = np.maximum(explanation, 0)\n",
    "    \n",
    "    # Normalize the explanation for visualization\n",
    "    explanation = normalize_ecg_relevancemap(explanation)\n",
    "    \n",
    "    # Add to explanations dictionary\n",
    "    explanations[method_name] = explanation\n",
    "    \n",
    "print(\"All explanations generated!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualize ECG Explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert explanations to proper shape for visualization\n",
    "def reshape_for_visualization(explanation):\n",
    "    # For 1D time series data, extract the values and flatten\n",
    "    if explanation.ndim == 3:  # [batch, channel, time]\n",
    "        return explanation[0, 0, :]\n",
    "    elif explanation.ndim == 4:  # [batch, channel, height, width]\n",
    "        # For GradCAM, the result might need to be resized\n",
    "        from scipy.interpolate import interp1d\n",
    "        orig_size = ecg_data.shape[0]\n",
    "        expl = explanation[0, 0]\n",
    "        if expl.shape[0] != orig_size:\n",
    "            x_orig = np.linspace(0, 1, expl.shape[0])\n",
    "            x_new = np.linspace(0, 1, orig_size)\n",
    "            f = interp1d(x_orig, expl, kind='linear')\n",
    "            return f(x_new)\n",
    "        return expl\n",
    "    return explanation\n",
    "\n",
    "# Process explanations\n",
    "processed_explanations = {}\n",
    "for method_name, explanation in explanations.items():\n",
    "    processed_explanations[method_name] = reshape_for_visualization(explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter explanations for better visualization (optional)\n",
    "posthresh = 0.2  # Threshold for filtering low values\n",
    "cmap_adjust = 0.3  # Adjust colormap for better visibility\n",
    "\n",
    "for method_name, explanation in processed_explanations.items():\n",
    "    # Filter low values\n",
    "    filtered_explanation = explanation.copy()\n",
    "    filtered_explanation[filtered_explanation <= posthresh] = 0\n",
    "    filtered_explanation[filtered_explanation > posthresh] += cmap_adjust\n",
    "    \n",
    "    # Update the explanations\n",
    "    processed_explanations[method_name] = filtered_explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure to visualize all explanations\n",
    "fig, axes = plt.subplots(len(processed_explanations), 1, figsize=(15, 4*len(processed_explanations)))\n",
    "\n",
    "for i, (method_name, explanation) in enumerate(processed_explanations.items()):\n",
    "    ax = axes[i] if len(processed_explanations) > 1 else axes\n",
    "    \n",
    "    # Plot the ECG\n",
    "    ax.plot(ecg_data, color='blue', alpha=0.7)\n",
    "    \n",
    "    # Create a colormap for the explanation\n",
    "    ax_twin = ax.twinx()\n",
    "    ax_twin.fill_between(range(len(ecg_data)), 0, explanation, \n",
    "                         color='red', alpha=0.5, label='Explanation')\n",
    "    ax_twin.set_ylim(0, 1.1)\n",
    "    ax_twin.set_ylabel('Relevance', color='red')\n",
    "    ax_twin.tick_params(axis='y', labelcolor='red')\n",
    "    \n",
    "    # Set title and labels\n",
    "    ax.set_title(f\"{method_name} Explanation\")\n",
    "    ax.set_xlabel('Time (samples)')\n",
    "    ax.set_ylabel('ECG Amplitude', color='blue')\n",
    "    ax.tick_params(axis='y', labelcolor='blue')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Interpretation of ECG Explanations\n",
    "\n",
    "Let's interpret what we're seeing in the ECG explanations:\n",
    "\n",
    "- **Gradient**: Shows the sensitivity of the model output to changes in the input ECG signal. Peaks often correspond to key cardiac events (P-waves, QRS complexes, T-waves).\n",
    "\n",
    "- **Gradient × Input**: Enhances the gradient by multiplying it with the input signal, emphasizing areas where both the signal and its importance are high.\n",
    "\n",
    "- **GradCAM**: Adapts the Grad-CAM technique for 1D time series data, highlighting temporal regions that contributed most to the classification decision.\n",
    "\n",
    "- **Guided Backprop**: Creates sharper feature visualizations by modifying the backpropagation signal through ReLU layers.\n",
    "\n",
    "- **LRP-Z**: Layer-wise Relevance Propagation with the Z-rule propagates the prediction backward through the network to identify relevant input features.\n",
    "\n",
    "- **LRP-Epsilon**: A variant of LRP that adds a stabilizing term (epsilon) to avoid division by zero, producing slightly different attribution maps.\n",
    "\n",
    "The highlighted regions in the ECG indicate which parts of the signal were most important for the model's prediction. In cardiology, these regions often correspond to specific cardiac events like abnormal QRS complexes or ST-segment abnormalities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Using SignXAI's TensorFlow API with PyTorch for Time Series\n",
    "\n",
    "As in the image example, we can use SignXAI's TensorFlow-style API even with our PyTorch model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the TensorFlow-style API\n",
    "from signxai.torch_signxai import tf_calculate_relevancemap\n",
    "\n",
    "# Use the TensorFlow-style API with PyTorch model\n",
    "methods_tf_style = ['gradient', 'gradient_x_input', 'guided_backprop', 'lrp_z', 'lrp_epsilon_0_1']\n",
    "explanations_tf_style = {}\n",
    "\n",
    "for method in methods_tf_style:\n",
    "    print(f\"Generating explanation using TF-style API: {method}...\")\n",
    "    \n",
    "    # Using the TensorFlow-style API with PyTorch model\n",
    "    explanation = tf_calculate_relevancemap(method, ecg_tensor, ecg_model_no_softmax)\n",
    "    \n",
    "    # Process for visualization\n",
    "    explanation = np.maximum(explanation, 0)  # Only use positive values\n",
    "    explanation = normalize_ecg_relevancemap(explanation)\n",
    "    explanation = reshape_for_visualization(explanation)\n",
    "    \n",
    "    # Filter low values\n",
    "    explanation[explanation <= posthresh] = 0\n",
    "    explanation[explanation > posthresh] += cmap_adjust\n",
    "    \n",
    "    # Store explanation\n",
    "    explanations_tf_style[method] = explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure to visualize TF-style API results\n",
    "fig, axes = plt.subplots(len(explanations_tf_style), 1, figsize=(15, 4*len(explanations_tf_style)))\n",
    "\n",
    "for i, (method_name, explanation) in enumerate(explanations_tf_style.items()):\n",
    "    ax = axes[i] if len(explanations_tf_style) > 1 else axes\n",
    "    \n",
    "    # Plot the ECG\n",
    "    ax.plot(ecg_data, color='blue', alpha=0.7)\n",
    "    \n",
    "    # Create a colormap for the explanation\n",
    "    ax_twin = ax.twinx()\n",
    "    ax_twin.fill_between(range(len(ecg_data)), 0, explanation, \n",
    "                         color='green', alpha=0.5, label='Explanation')\n",
    "    ax_twin.set_ylim(0, 1.1)\n",
    "    ax_twin.set_ylabel('Relevance', color='green')\n",
    "    ax_twin.tick_params(axis='y', labelcolor='green')\n",
    "    \n",
    "    # Set title and labels\n",
    "    ax.set_title(f\"TF-API: {method_name} Explanation\")\n",
    "    ax.set_xlabel('Time (samples)')\n",
    "    ax.set_ylabel('ECG Amplitude', color='blue')\n",
    "    ax.tick_params(axis='y', labelcolor='blue')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Conclusion\n",
    "\n",
    "In this tutorial, we've demonstrated how to use SignXAI to explain predictions of ECG models in PyTorch. We've covered:\n",
    "\n",
    "- Creating a PyTorch model for ECG classification\n",
    "- Loading and preprocessing ECG time series data\n",
    "- Applying various explainability methods to ECG signals\n",
    "- Visualizing and interpreting explanations\n",
    "- Using SignXAI's TensorFlow-style API with PyTorch models\n",
    "\n",
    "These techniques help medical professionals understand what parts of the ECG signal are contributing to the model's predictions, potentially enhancing trust and enabling model validation for clinical use.\n",
    "\n",
    "The ability to seamlessly switch between PyTorch and TensorFlow APIs demonstrates SignXAI's versatility, making it a valuable tool for researchers and practitioners working with either framework."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}