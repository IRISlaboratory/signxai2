"""
Unified API for SignXAI package.

This module provides a consistent API for both TensorFlow and PyTorch backends,
ensuring that methods and parameters are aligned between the frameworks.
"""
import numpy as np
from typing import Union, Optional, Dict, Any, List, Tuple


def calculate_relevancemap(
        model,
        inputs,
        method: str,
        framework: Optional[str] = None,
        target_class: Optional[Union[int, np.ndarray]] = None,
        **kwargs
) -> np.ndarray:
    """
    Unified interface for calculating relevance maps with either TensorFlow or PyTorch.
    
    This function provides a consistent interface for explanation methods across frameworks
    by automatically detecting the framework or using the specified one.
    
    Args:
        model: Model to explain (TensorFlow or PyTorch)
        inputs: Input tensor/array for the model
        method: Name of the explanation method to use
        framework: Optional specification of framework ('tensorflow' or 'pytorch')
        target_class: Target class to explain (optional)
        **kwargs: Additional method-specific parameters
    
    Returns:
        np.ndarray: Calculated relevance map
    
    Raises:
        ValueError: If framework cannot be determined or is unsupported
    """
    import sys
    
    # Detect framework if not specified
    if framework is None:
        if 'tensorflow' in sys.modules and hasattr(model, 'layers'):
            framework = 'tensorflow'
        elif 'torch' in sys.modules and hasattr(model, 'parameters'):
            framework = 'pytorch'
        else:
            raise ValueError(
                "Could not determine framework from model. "
                "Please specify framework='tensorflow' or framework='pytorch'."
            )
    
    framework = framework.lower()
    if framework not in ['tensorflow', 'pytorch']:
        raise ValueError(f"Unsupported framework: {framework}. Use 'tensorflow' or 'pytorch'.")
    
    # Prepare parameters with consistent naming
    # Map generic parameters to framework-specific parameters
    params = kwargs.copy()
    
    # Handle the target class parameter (different naming conventions)
    if target_class is not None:
        if framework == 'tensorflow':
            params['neuron_selection'] = target_class
        else:  # pytorch
            params['target_class'] = target_class
    
    # Parameter mapping between frameworks
    param_mapping = {
        # TensorFlow to PyTorch
        'tensorflow': {
            'integrated_gradients': {
                'steps': 'steps',
                'reference_inputs': 'baseline'
            },
            'smoothgrad': {
                'augment_by_n': 'num_samples',
                'noise_scale': 'noise_level'
            },
            'grad_cam': {
                'last_conv_layer_name': 'target_layer'
            }
        },
        # PyTorch to TensorFlow
        'pytorch': {
            'integrated_gradients': {
                'steps': 'steps',
                'baseline': 'reference_inputs'
            },
            'smoothgrad': {
                'num_samples': 'augment_by_n',
                'noise_level': 'noise_scale'
            },
            'grad_cam': {
                'target_layer': 'last_conv_layer_name'
            }
        }
    }
    
    # Method name mapping between frameworks
    method_name_mapping = {
        'tensorflow': {
            'gradient': 'gradient',
            'integrated_gradients': 'integrated_gradients',
            'smoothgrad': 'smoothgrad',
            'grad_cam': 'grad_cam',
            'guided_backprop': 'guided_backprop',
            'deconvnet': 'deconvnet',
            'deeplift': 'deeplift',
            'lrp.epsilon': 'lrp_epsilon',
            'lrp.z': 'lrp_z',
            'lrp.z_plus': 'lrp_z',  # TF uses z, PyTorch uses z_plus
            'lrp.w_square': 'lrp_w_square',
            'lrp.flat': 'lrp_flat',
            'lrp.alpha_1_beta_0': 'lrp_alpha_1_beta_0',
            'lrp.alpha_2_beta_1': 'lrp_alpha_2_beta_1',
            'lrp.gamma': 'lrp_gamma',
        },
        'pytorch': {
            'gradient': 'gradient',
            'integrated_gradients': 'integrated_gradients',
            'smoothgrad': 'smoothgrad',
            'grad_cam': 'grad_cam',
            'guided_backprop': 'guided_backprop',
            'deconvnet': 'deconvnet',
            'deeplift': 'deeplift',
            'lrp_epsilon': 'lrp.epsilon',
            'lrp_z': 'lrp.z_plus',  # TF uses z, PyTorch uses z_plus
            'lrp_w_square': 'lrp.w_square',
            'lrp_flat': 'lrp.flat',
            'lrp_alpha_1_beta_0': 'lrp.alpha_1_beta_0',
            'lrp_alpha_2_beta_1': 'lrp.alpha_2_beta_1',
            'lrp_gamma': 'lrp.gamma',
        }
    }
    
    # Standardize method name
    original_method = method
    
    # For TensorFlow, get standard name
    if framework == 'tensorflow':
        if method in method_name_mapping['tensorflow']:
            method = method_name_mapping['tensorflow'][method]
    
        # Apply parameter mapping for TensorFlow
        if original_method in param_mapping['tensorflow']:
            mapping = param_mapping['tensorflow'][original_method]
            for src_param, dst_param in mapping.items():
                if src_param in params:
                    params[dst_param] = params.pop(src_param)
    
        # Import and call TensorFlow function (lazy import)
        try:
            from signxai.tf_signxai.methods.wrappers import calculate_relevancemap as tf_calculate_relevancemap
            return tf_calculate_relevancemap(m=method, x=inputs, model_no_softmax=model, **params)
        except ImportError as e:
            raise ImportError(
                f"Could not import signxai.tf_signxai: {e}. "
                "Make sure TensorFlow and SignXAI[tensorflow] are installed."
            )
    
    elif framework == 'pytorch':
        # For PyTorch, get standard name
        if method in method_name_mapping['pytorch']:
            method = method_name_mapping['pytorch'][method]
    
        # Apply parameter mapping for PyTorch
        if original_method in param_mapping['pytorch']:
            mapping = param_mapping['pytorch'][original_method]
            for src_param, dst_param in mapping.items():
                if src_param in params:
                    params[dst_param] = params.pop(src_param)
    
        # Import and call PyTorch function (lazy import)
        try:
            from signxai.torch_signxai.methods.wrappers import _calculate_relevancemap as pt_calculate_relevancemap
            return pt_calculate_relevancemap(model=model, input_tensor=inputs, method=method, **params)
        except ImportError as e:
            raise ImportError(
                f"Could not import signxai.torch_signxai: {e}. "
                "Make sure PyTorch and SignXAI[pytorch] are installed."
            )


def calculate_relevancemaps(
        model,
        inputs_batch,
        method: str,
        framework: Optional[str] = None,
        target_classes: Optional[Union[List[int], np.ndarray]] = None,
        **kwargs
) -> List[np.ndarray]:
    """
    Calculate relevance maps for a batch of inputs.
    
    Args:
        model: Model to explain (TensorFlow or PyTorch)
        inputs_batch: Batch of input tensors/arrays
        method: Name of the explanation method to use
        framework: Optional specification of framework ('tensorflow' or 'pytorch')
        target_classes: List of target classes to explain (optional)
        **kwargs: Additional method-specific parameters
    
    Returns:
        List[np.ndarray]: List of calculated relevance maps
    """
    results = []
    
    # Process each input separately to ensure consistent handling
    for i, inputs in enumerate(inputs_batch):
        # Get target class for this specific input if available
        target_class = None
        if target_classes is not None and i < len(target_classes):
            target_class = target_classes[i]
        
        # Calculate relevance map for this input
        relevance_map = calculate_relevancemap(
            model=model,
            inputs=inputs,
            method=method,
            framework=framework,
            target_class=target_class,
            **kwargs
        )
        
        results.append(relevance_map)
    
    return results